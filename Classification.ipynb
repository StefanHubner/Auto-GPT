{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTxDZZE/SrxoeLOt5q+w+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StefanHubner/Auto-GPT/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "bazuD2aDpbkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probability"
      ],
      "metadata": {
        "id": "7IvKDavUubzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language and Notation\n",
        "\n",
        "The set of all possible outcomes of an experiment is called the **sample space** which we will denote by $ \\Omega $ (e.g. $ \\Omega = \\left\\{ HH, HT, TH, TT \\right\\} $). We refer to its elements $ \\omega \\in \\Omega $ as elementary events.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "An **event** is a subset of the sample space $ A \\subseteq \\Omega $. It allows us to define statements such as \"at least one head occurs\" with corresponding event $ A = \\{HH, HT, TH\\} $.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We call the set of all possible events a **sigma-algebra** which is denoted by $ \\mathcal{F} = \\sigma(\\Omega) $. This includes the **null event** $ \\emptyset $ and the **sure event** $ \\Omega $.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "A **probability measure** $P$ is a function that takes an event and measures how likely it will occur (e.g. for a fair coin we know that $ P(\\{HH\\}) = \\frac{1}{4} $).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "A **probability space** is a triple $ (\\Omega, \\mathcal{F}, P) $."
      ],
      "metadata": {
        "id": "piiAAHXeu76P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probability Measure\n",
        "\n",
        "#### Definition\n",
        "\n",
        "1. $P(A) \\geq 0$ for any event $A \\subseteq \\Omega$,\n",
        "\n",
        "2.  $P(\\Omega) =1$,\n",
        "\n",
        "3. If subsets $A_n\\in\\Omega,n=1,2,...$ are disjoint (do not intersect),\n",
        "then $P( \\bigcup_{n=1}^{\\infty} A_n) =\n",
        "\\sum_{n=1}^{\\infty} P(A_n)$. This is called countable additivity.\n",
        "\n",
        "\n",
        "A few results that could be derived from the definition:\n",
        "\n",
        "* $P(\\emptyset) =0$,\n",
        "* $P(\\Omega \\setminus A)  =1 - P(A)$, where $\\Omega \\setminus A = \\{\\omega \\notin A \\}$,\n",
        "* If $A\\subseteq B$ then $P(A) \\leq P(B)$,\n",
        "* $P(A\\cup B) =P(A) + P(B) - P( A\\cap B)$,\n",
        "* For any sets $A_{n}$,\n",
        "$P( \\bigcup_{n=2}^{\\infty} A_n ) \\leq \\sum\\nolimits_{n=1}^{\\infty}P( A_n )$.\n",
        "\n",
        "\n",
        "We can define different probability functions (e.g., $P_1, P_2, P_3$) on the same sample space\n",
        "\n",
        "### Random Variables\n",
        "\n",
        "A **random variable** $X$ is a function from ($\\Omega$, $\\mathcal{F}) $ into $ (\\mathbb{R}, \\mathcal{B}) $ connecting an elementary event $ \\omega $ to a real valued outcome.\n",
        "\n",
        "\n",
        "> For example, let's assume we have two coloured dice and define their respective face values as two random variables $X(⚄⚂) = 5, Y(⚄⚂) = 3$. Their value tells us that for outcome $\\omega_{53} = ⚄⚂ $ the\n",
        "random variable $X$ will have realised value $5$ and the random variable $Y$ will have realised value $3$.\n",
        "\n",
        "\n",
        "When we write a formula with random variables, the formula defines a new function:\n",
        "$$ Z : \\Omega \\to \\mathbb{R} : \\omega \\mapsto X(\\omega)+ Y(\\omega) $$\n",
        "We usually write the short hand definition $ Z = X + Y $ but keep this definition in mind!\n",
        "\n",
        "---\n",
        "\n",
        "Think of all random variables as simultaneously determined by the outcome $\\omega$.\n",
        "Any expression you construct from random variables is also uniquely determined\n",
        "by the outcome $\\omega$.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\begin{array}{llcccccc}\n",
        "&  & X_1 & X_2 & X_3 & Y & X_3 / Y & \\dots \\\\\n",
        "\\omega _{1} & ~ & 0 & 0 & 0 & 1.5 & 0 & \\dots \\\\\n",
        "\\omega _{2} & ~ & 0 & 3 & 3 & 2 & 1.5 & \\dots \\\\\n",
        "\\omega _{3} & ~ & 1 & 0 & 1 & 1 & 1 & \\dots \\\\\n",
        "\\omega _{4} & ~ & 2 & 1 & 4 & 0.5 & 8 & \\dots \\\\\n",
        "... & ~ & ... & ... & ... & ... & ... & \\dots\n",
        "\\end{array}%\n",
        "\\end{equation*}\n",
        "\n",
        "---\n",
        "\n",
        "### Measuring Events\n",
        "\n",
        "The probability measure $P$ determines how likely different $\\omega$'s are to happen and, consequently, values for $ X_{1}, X_{2},X_{3},Y$ and their functions.\n",
        "\n",
        "We often want to make statements not only involving an elementary event $ \\omega \\in \\Omega$ but instead a collection $ A \\in \\mathcal{F} $ of them.\n",
        "\n",
        "We can then define the corresponding event for the random variable as $\\{\\omega: Z(\\omega) \\in B \\}$ where $ B \\in \\mathcal{B} $, the Borel sigma-algebra defined as the smallest set of all open intervals on $ \\mathbb{R} $.\n",
        "\n",
        "If we write $P(\\dots)$ around the statement, we mean the probability assigned by measure $P$ to the event described in parentheses e.g.\n",
        "$$\n",
        "P(\\{\\omega: Z(\\omega) \\in (a,b) \\}) = P(Z \\in (a,b)) = P (a < Z < b).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "> In our two dice example we might want to be interested in the event that corresponds to the sum of the eyes as $ Z = X + Y $ being less or equal to 3.\n",
        "\n",
        "> For this, we can define the event $ B = (0, 3] \\in \\mathcal{B} $ that their sum is less or equal than 3.\n",
        "$$ A = \\{\\omega: Z(\\omega) \\in (0, 3] \\} =\n",
        "\\{ ⚀⚀, ⚀⚁, ⚀⚁\\}$$\n",
        "\n",
        "We can then measure this event with different probability measures.\n",
        "\n",
        "> Let us denote as $ P_0 $ the probability measure corresponding to a fair dice that gives equal likelihood $ P_0(\\omega) = \\frac{1}{36} $ to all elementary events $ \\omega \\in \\Omega $. In this case we get $ P(A) = \\frac{3}{36} = \\frac{1}{12} $.\n",
        "\n",
        "#### Absolute continuity\n",
        "\n",
        "An elementary element in $ \\mathbb{R} $ is a point,  which is (losely speaking) an interval $ B \\in \\mathcal{B} $ of width zero. We sometimes call these intervals to have zero (Lebesque) measure.\n",
        "\n",
        "If a probability measure for a random variable $ X $gives zero probability to **any zero-measure intervals**, we call the random variable $ X $ a **continuous random variable**.\n",
        "\n",
        "If **every zero-measure interval** in the image of a random variable $ Y $ is given non-zero probability by it's probability measure, we call the random variable $ Y $ discrete.\n",
        "\n",
        "There are also **mixed** random variables.\n",
        "\n",
        "> In our example, the image of $ Z $ is $ \\{ 2, \\ldots\\, 12 \\} $. For any of these points $ P_0 $ associates a probability to the corresponding event of $ \\frac{1}{36} > 0 $.\n",
        "\n",
        "#### Distribution Functions\n",
        "\n",
        "Instead of working with general probability measures, we will often distinguish discrete and continuous random variables and work with distribution functions:\n",
        "\n",
        "$$ F_{X}(x) = P(X \\leq x) $$\n",
        "\n",
        "For a **continuous** random variable there exists a function $f_{X}(x) \\geq 0$, called the **probability density function**, satisfying\n",
        "$$\n",
        "F_{X}(x) = \\int_{-\\infty }^{x}f_{X}(t)dt \\text{ for all } x \\in \\mathbb{R}.\n",
        "$$\n",
        "\n",
        "In this case we can measure:\n",
        "$$ P(a < X < b) = F_X(b) - F_X(a) = \\int_{a}^{b}f_{X}(t)dt $$\n",
        "by the **fundamental theorem of calculus**.\n",
        "\n",
        "\n",
        "\n",
        "> *Exercise: Use the probability of the sure event to show that any density function must satisfy* $\\int_{-\\infty}^{\\infty} f_X(x)dx = 1$.\n",
        "\n",
        "If the random variable $X$ is **discrete** we have\n",
        "$$\n",
        "\\sum_{k=1}^{\\infty} P(X = x_k) = 1\n",
        "$$\n",
        "for some (possibly uncountable) sequence of numbers $\\{x_1, x_2, x_3, \\dots \\}$.\n",
        "\n",
        "\n",
        "We call $p(x_k) = P(X=x_k)$ the **probability mass function** of $X$.\n",
        "\n",
        "### Moments\n",
        "\n",
        "The **expectation** for any (measurable) function m is\n",
        "$$\n",
        "\\mathbb{E} m(X) = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "\\sum\\limits_{k=1}^{\\infty} m(x_k) P(X = x_k)\n",
        " & \\text{ if $X$ is discrete}, \\\\\n",
        "\\int\\limits_{-\\infty}^{\\infty} m(x) f_X(x) dx\n",
        " & \\text{ if $X$ is continuous}.\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "**Special cases**:\n",
        "* Expected Value: $ m_1(X) = X $\n",
        "* Variance: $ m_2(X) = (X - m_1(X))^2 $\n",
        "* Covariance: $ m_3(X, Y) = (X - m_1(X))(Y - m_1(Y)) $\n",
        "\n",
        "### Independence\n",
        "Events $\\{ A_{k},k = 1,2,\\dots n\\}$ are **independent**\n",
        "$$\n",
        "    P\\hspace{-2ex}\\underbrace{\\left( \\bigcap_{k=1}^{n} A_k \\right)}_{\\text{intersection of sets}} \\hspace{-1.5ex} = \\prod_{k=1}^{n}  P\\left( A_k \\right).\n",
        "$$\n",
        "\n",
        "~\n",
        "\n",
        "This leads to a definition of **independent random variables** $\\{X_1, X_2, \\dots, X_n\\}$  if\n",
        "$$\n",
        "P\\underbrace{( X_1 \\in B_1, X_2 \\in B_2, \\dots X_n \\in B_n )}_{\\text{all true }}\n",
        "= \\prod\\limits_{k=1}^{n} P( X_k \\in B_k )\n",
        "$$\n",
        "for any sets of real numbers $B_1, \\dots, B_n \\in \\mathcal{B} $.\n",
        "\n",
        "\n",
        "Consequently, random variables are **independent** if their **conditional probability**\n",
        "$$ P(X_1 \\in B_1 | X_2 \\in B_2) = \\frac{P(X_1 \\in B_1, X_2 \\in B_2)}{P(X_2 \\in B_2)} = P(X_1 \\in B_1) . $$\n"
      ],
      "metadata": {
        "id": "XSPeMs7sw33_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maximum Likelihood Recap"
      ],
      "metadata": {
        "id": "Kza7Wy7Epcsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume we have $ n $ independent copies of random variables $ X_1, \\ldots, X_n $ with $ P(X_i \\leq x) = P_{\\theta}(X_i \\leq x) = F_{\\theta}(x) $ with corresponding p.d.f or p.m.f. $ f(x|\\theta) $."
      ],
      "metadata": {
        "id": "XrLVzXYSq1NL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S4ZhudTXrKES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, the likelihood that we observe realisations $ (x_1, \\ldots x_n) $\n",
        "$$ f(x_1, \\ldots, f_n | \\theta) =\\prod\\limits_{i=1}^n f_i(x_i, \\theta) =\\prod\\limits_{i=1}^n f(x_i, \\theta)  $$\n",
        "\n",
        "where the first equality follows from independence and the second from\n",
        "the identical distribution."
      ],
      "metadata": {
        "id": "MOUuQv9wpooO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f2cYGn7Jq0LV"
      }
    }
  ]
}